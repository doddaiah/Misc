http://ai.stanford.edu/courses/
stanford deep learning homepagehttp://deeplearning.stanford.edu/
stanford  papershttp://ufldl.stanford.edu/?papers
stanford wiki deeplearning pages and tutorials
http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Recommended_Readings
stanford UFLDL tutorialshttp://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial
andrews Ng tutorialshttp://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning
yann lecun webpage and mnist
http://yann.lecun.com/exdb/mnist/


http://forum.stanford.edu/events/2017plenary.php

https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/ 

https://stp.lingfil.uu.se/~nivre/

https://arxiv.org/archive/cs

http://people.idsia.ch/~juergen/

http://deeplearning.net/tutorial/lstm.html

http://www.statmt.org/wmt16/

http://introtodeeplearning.com/schedule.html
MIT S191 Schedule

http://www.statmt.org/wmt06/proceedings/

https://www.youtube.com/watch?v=IgSuFYamZas

model-free reinforcement learning

reinforcement learning indepth
http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html

straight through estimator
https://r2rt.com/binary-stochastic-neurons-in-tensorflow.html

gumbel softmax from nlp stanford
gumbel and straight through estimator or other models instead of reinforcement methods for non differentiable points.
http://blog.evjang.com/2016/11/tutorial-categorical-variational.html
https://casmls.github.io/general/2017/02/01/GumbelSoftmax.html

https://en.wikipedia.org/wiki/Q-learning

Basics

ML Crash Course https://ml.berkeley.edu/blog/2016/11/06/tutorial-1/

Cross entropy http://colah.github.io/posts/2015-09-Visual-Information/

Python tutorial: http://www.learnpython.org/

Python/Numpy tutorial: http://cs231n.github.io/python-numpy-tutorial/

Reference for math/probability: chapter 2, 3 and 4 of http://www.deeplearningbook.org/

Tensorflow Crash Course: http://nicklocascio.com/tensorflow-crash-course


Deep Learning, foundations

Intro-level deep learning book: http://neuralnetworksanddeeplearning.com/

Advanced deep learning book: http://www.deeplearningbook.org/

Lots of links to topics: http://yerevann.com/a-guide-to-deep-learning/

Deep Learning/TensorFlow Udacity Course: https://www.udacity.com/course/deep-learning--ud730

Yann LeCun’s ‘Efficient Backpropagation’ (goes through a lot of basics on how/why to train networks a certain way, including some theory behind it): yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf


Deep Learning, advanced/state-of-the-art: 

Guide to Papers: https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap

Curating arXiv: arxiv-sanity.com

Summaries of Papers: http://www.shortscience.org/

Papers from Conferences: 
NIPS: https://nips.cc/Conferences/2016/AcceptedPapers
ICLR: https://openreview.net/group?id=ICLR.cc/2017/conference
ICML: http://icml.cc/2016/?page_id=1649
KDD: http://www.kdd.org/kdd2016/program/accepted-papers

Blogs etc: 

Deep Learning Newsletter: http://www.wildml.com/newsletter/

ML subreddit: https://www.reddit.com/r/MachineLearning/

Andrej Karpathy’s blog: http://karpathy.github.io/

Chris Olah’s blog: http://colah.github.io/


More on specific topics: 

RNNs / Sequential Modeling: 
Attention & Memory: http://distill.pub/2016/augmented-rnns/
Stanford CS 224 slides: http://cs224d.stanford.edu/syllabus.html
LSTMs, vanishing gradient: http://harinisuresh.com/2016/10/09/lstms/
Vanishing Gradient: http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem



CNNs / Vision:


Multimodal Problems: 


Generative Models: 


Reinforcement Learning: 


http://www.iro.umontreal.ca/~bengioy/talks/




CS231N winter 2017 invited talk by Jeff Dean time 1:04:35
1)
research.google.com/archive/unsupervised_icml2012.html

2)research.google.com/archive/large_deep_networks_nips2012.hmtl
3)arxiv.org/abs/1301.3781
4)arxiv.org/abs/1405.4053
5)arxiv.org/abs/1409.3215
6)arxiv.org/abs/1411/4555
7)tensorflow.org/whitepaper2015.pdf
research.google.com/people/jeff
research.google.com/pubs/machineintelligence.html



http://allenai.org/semantic-scholar/
arxiv.org
semanticscholar.og
http://www.iclr.cc/doku.php?id=iclr2015:main


https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/https://ronxin.github.io/wevi/
https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/
https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/
https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/
https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/
https://rare-technologies.com/fasttext-and-gensim-word-embeddings/
https://nlp.stanford.edu/projects/glove/
https://nlp.stanford.edu/projects/glove/
5. Important Libraries for NLP (python)
Scikit-learn: Machine learning in PythonNatural Language Toolkit (NLTK): The complete toolkit for all NLP techniques.Pattern – A web mining module for the with tools for NLP and machine learning.TextBlob – Easy to use nl p tools API, built on top of NLTK and Pattern.spaCy – Industrial strength N LP with Python and Cython.Gensim – Topic Modelling for HumansStanford Core NLP – NLP services and packages by Stanford NLP Group.
